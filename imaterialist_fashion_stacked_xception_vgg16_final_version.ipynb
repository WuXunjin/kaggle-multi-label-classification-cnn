{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal of this Kaggle competition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Link of Kaggle competition: https://www.kaggle.com/c/imaterialist-challenge-fashion-2018\n",
    "- As shoppers move online, it would be a dream come true to have products in photos classified automatically\n",
    "- Although different fine-grained categories may look very similar (royal blue vs turquoise in color), it would be ideal to build a model able to perceive such subtle differences between photos, as these differences could be important for shopping decisions\n",
    "- This Kaggle competition challenges us to accurately assign attribute labels for fashion images\n",
    "- There are 228 distinct labels and our training dataset contains 1 million images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download raw images from given URLs and resize them into a 112*112 RGB pixel format to build datasets\n",
    "2. Build two base CNN (convolutional neural networks) models: one Xception architecture and one VGG16 model outputting labels probabilities\n",
    "3. Build a meta learner neural network model taking as inputs the two base learners outputs and outputting the labels probabilities \n",
    "4. Measure F1 score performance of meta-learner on validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ranked 10th out of 212 teams (top 5%) at competition closure time (username “yasserez05” in the final private leaderboard)\n",
    "- F1 score of 0.65 on test dataset (highest score of competition is 0.71)\n",
    "- 3 Keras models (total size of 170MB) fully trained and usable for predicting labels of new images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import urllib\n",
    "from urllib.error import HTTPError\n",
    "import concurrent.futures\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage import io\n",
    "from skimage.transform import rescale, resize, rotate\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Activation, Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.applications import vgg16, vgg19, inception_v3, resnet50, mobilenet, xception, nasnet, densenet\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define key parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## How many GPUs will you use in your server (need to be an even number)\n",
    "number_of_gpus = 2\n",
    "\n",
    "## How many images we want to download for the train dataset\n",
    "train_number_images = 200000\n",
    "\n",
    "## Define batch size that will be used for our CNN models\n",
    "batch_size = 16\n",
    "\n",
    "## Define folders where to save resized images downloaded from Kaggle provided urls\n",
    "train_images_folder = 'train_images_resized'\n",
    "validation_images_folder = 'val_images_resized'\n",
    "test_images_folder = 'test_images_resized'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download images, resize them and save them in output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import json file and transform it into metadata file (image_id, labels_id, image_urls)\n",
    "\n",
    "def load_metadata(json_name, is_test_data = False):\n",
    "    temp_json = json.load(open(json_name))\n",
    "    \n",
    "    if not is_test_data:\n",
    "        temp_metadata_urls = pd.DataFrame(temp_json['images'])\n",
    "        temp_metadata_labels = pd.DataFrame(temp_json['annotations'])\n",
    "        \n",
    "        temp_metadata = pd.merge(temp_metadata_labels\n",
    "                                 , temp_metadata_urls\n",
    "                                 , how = 'inner'\n",
    "                                 , on = 'imageId')\n",
    "\n",
    "        temp_metadata.columns = ['image_id', 'labels_id', 'image_url']\n",
    "        \n",
    "        del (temp_metadata_urls, temp_metadata_labels)\n",
    "    \n",
    "    else:\n",
    "        temp_metadata = pd.DataFrame(temp_json['images'])\n",
    "        temp_metadata.columns = ['image_id', 'image_url']\n",
    "        \n",
    "    del (temp_json)\n",
    "    \n",
    "    return temp_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load train, validation and test metadata\n",
    "\n",
    "train_metadata = load_metadata('train.json', is_test_data = False)\n",
    "val_metadata = load_metadata('validation.json', is_test_data = False)\n",
    "test_metadata = load_metadata('test.json', is_test_data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Show example of how to load data from URL, resize it and display it\n",
    "\n",
    "url = val_metadata['image_url'][10]\n",
    "response = urllib.request.urlopen(url)\n",
    "buf = BytesIO(response.read())\n",
    "img = Image.open(buf)\n",
    "img = np.array(img)\n",
    "img_resized = resize(img, (112,112))\n",
    "io.imshow(img_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define function that will download images, resize them and save them in output folder\n",
    "## This function takes one input that is a tuple of 3 elements so that it can be used by the multi-threading operation in next cell\n",
    "\n",
    "def download_resize_save_img(image_id_url_folder):\n",
    "    image_id, url, image_folder = image_id_url_folder\n",
    "    response = urllib.request.urlopen(url)\n",
    "    buf = BytesIO(response.read())\n",
    "    img = Image.open(buf)\n",
    "    img = np.array(img)\n",
    "    img_resized = resize(img, (112,112))\n",
    "    image_filename = str('image_id' + str(image_id) + '.jpg')\n",
    "    image_path = os.path.join(image_folder, image_filename)\n",
    "    io.imsave(image_path, img_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define function that will download images in multi-threading\n",
    "\n",
    "def download_images_from_metadata(metadata, output_folder, number_images):\n",
    "        ## Create input list of tuples for the multi-threading operation below\n",
    "    image_id_url_folder = list(zip(metadata['image_id'][:number_images]\n",
    "                                   , metadata['image_url'][:number_images]\n",
    "                                   , [output_folder]*number_images))\n",
    "\n",
    "        ## Download images in multi-threading\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        executor.map(download_resize_save_img, image_id_url_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Download train images in multi-threading\n",
    "\n",
    "download_images_from_metadata(train_metadata, train_images_folder, train_number_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Download validation images in multi-threading\n",
    "\n",
    "download_images_from_metadata(val_metadata, val_images_folder, val_metadata.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Download test images in multi-threading\n",
    "\n",
    "download_images_from_metadata(test_metadata, test_images_folder, test_metadata.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset_for_X_and_y(images_folder, number_images, metadata, is_test_data = False):\n",
    "    data = []\n",
    "    \n",
    "    for image_filename in os.listdir(images_folder)[:number_images]:\n",
    "        img = io.imread(os.path.join(images_folder, image_filename), as_grey=False)\n",
    "        image_id = image_filename.split('.')[0] # image_filename is like \"image_id1000.jpg\"\n",
    "        image_id = image_id.split(\"image_id\")[1]\n",
    "        data.append({'image_id': image_id\n",
    "                       , 'image_array': img})\n",
    "    \n",
    "    data = pd.DataFrame(data)\n",
    "    \n",
    "    if not is_test_data: # for train and validation, we need to merge the labels to each observation\n",
    "        data = pd.merge(data\n",
    "                          , metadata\n",
    "                          , how = 'inner'\n",
    "                          , on = 'image_id')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create the train dataset that will be used for X_train and Y_train\n",
    "    \n",
    "    # Train data size needs to be a multiple of the batch size as each batch is divided equally to be sent to each GPU for training\n",
    "    # If one of the GPU receives a too small batch or none training data, it will return NaN weights and the model will be unusable\n",
    "train_data = create_dataset_for_X_and_y(train_images_folder, batch_size*11600, train_metadata, is_test_data = False)\n",
    "\n",
    "## Create the X_train array\n",
    "X_train = np.array(list(train_data['image_array']))\n",
    "X_train = X_train.astype('float32')/255 ## So that the array has values between 0 and 1\n",
    "\n",
    "## Create the y_train array\n",
    "y_train = list(train_data['labels_id'])\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train = mlb.fit_transform(y_train)\n",
    "\n",
    "num_labels = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create the validation dataset that will be used for X_val and Y_val\n",
    "\n",
    "# number of observations needs to be a multiple of batch size so we choose number of images = batch_size*618\n",
    "val_data = create_dataset_for_X_and_y(validation_images_folder, batch_size*618, val_metadata, is_test_data = False)\n",
    "\n",
    "## Create the X_val array\n",
    "X_val = np.array(list(val_data['image_array']))\n",
    "X_val = X_val.astype('float32')/255\n",
    "\n",
    "## Create the y_val array\n",
    "y_val = list(val_data['labels_id'])\n",
    "y_val = [list(set.intersection(set(labels), set(mlb.classes_))) for labels in y_val] # mlb breaks for unseen labels\n",
    "y_val = mlb.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create the test dataset that will be used for X_test\n",
    "\n",
    "test_data = create_dataset_for_X_and_y(test_images_folder, 10, test_metadata, is_test_data = True)\n",
    "\n",
    "## Create the X_val array\n",
    "X_test = np.array(list(test_data['image_array']))\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build CNN models following below architecture:\n",
    "## 1) Create first base learner using Xception architecture\n",
    "## 2) Create second base learner using VGG16 architecture\n",
    "## 3) Create a blending NN model taking as input the two base learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception base learner model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Construct xception model\n",
    "\n",
    "    ## Load base xception model\n",
    "\n",
    "base_xception = xception.Xception(weights = 'imagenet', include_top = False, input_shape = X_train.shape[1:])\n",
    "\n",
    "    ## If we want to freeze layers of base model so that they are not trained\n",
    "# for layer in base_xception.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    # initialize the model\n",
    "    x = Flatten()(base_xception.output)\n",
    "    # For a multi label classification, the activation function needs to be \"sigmoid\"\n",
    "    predictions = Dense(num_labels, activation = 'sigmoid')(x)\n",
    "    model_xception = Model(input = base_xception.input, output = predictions)\n",
    "\n",
    "    # Make sure to keep a non-gpu version of the model so that it can be saved, the gpu and non-gpu model share the same weights\n",
    "model_xception_gpu = multi_gpu_model(model_xception, gpus = number_of_gpus)\n",
    "\n",
    "    # For a multi label classification, the loss needs to be \"binary_crossentropy\"\n",
    "model_xception_gpu.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_xception_gpu.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Fit model\n",
    "\n",
    "## use history = model.fit so you can plot later the loss plot\n",
    "model_history = model_xception_gpu.fit(X_train, y_train,\n",
    "                                       batch_size = 16,\n",
    "                                       epochs= 10,\n",
    "                                       validation_data = (X_val, y_val),\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot training accuracy\n",
    "\n",
    "plt.plot(model_history.history['acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Save xception model trained\n",
    "\n",
    "model_xception.save('model_xception.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load xception model trained\n",
    "\n",
    "# model_xception = load_model('model_xception.h5')\n",
    "\n",
    "# model_xception_gpu = multi_gpu_model(model_xception, gpus = number_of_gpus)\n",
    "\n",
    "# model_xception_gpu.compile(loss='binary_crossentropy', # try hinge loss function\n",
    "#                            optimizer=keras.optimizers.Adadelta(),\n",
    "#                            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Calculate predictions in validation dataset\n",
    "\n",
    "y_val_pred_xception = model_xception_gpu.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Predict labels\n",
    "\n",
    "threshold = 0.22 # Choose different thresholds\n",
    "y_val_pred_label_xception = y_val_pred_xception.copy()\n",
    "y_val_pred_label_xception[y_val_pred_xception>=threshold] = 1\n",
    "y_val_pred_label_xception[y_val_pred_xception<threshold] = 0\n",
    "\n",
    "## Calculate F1 score micro average\n",
    "f1_score_micro_xception = f1_score(y_true=y_val, y_pred=y_val_pred_label_xception, average='micro')\n",
    "f1_score_micro_xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Find the best combination of thresholds that will give you the best F1-score via simulation\n",
    "\n",
    "thresholds_to_try = np.random.rand(100000, num_labels)\n",
    "best_thresholds_xception = []\n",
    "best_f1_score_xception = 0\n",
    "y_val_pred_label_xception = y_val_pred_xception.copy()\n",
    "\n",
    "for list_thresholds in thresholds_to_try:\n",
    "    y_val_pred_label_xception = y_val_pred_xception.copy()\n",
    "    y_val_pred_label_xception[y_val_pred_xception >= list_thresholds] = 1\n",
    "    temp_y_val_pred_label_xception[y_val_pred_xception < list_thresholds] = 0\n",
    "    temp_f1_score = f1_score(y_true=y_val, y_pred=temp_y_val_pred_label_xception, average='micro')\n",
    "    if temp_f1_score > best_f1_score:\n",
    "        best_f1_score_xception = temp_f1_score\n",
    "        best_thresholds_xception = list_thresholds\n",
    "        y_val_pred_label_xception = temp_y_val_pred_label_xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Output best F1 score of Xception base learner\n",
    "\n",
    "print(best_f1_score_xception)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 base learner model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Build VGG16 model\n",
    "\n",
    "base_vgg16 = vgg16.VGG16(weights = 'imagenet', include_top = False, input_shape = X_train.shape[1:])\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    #initialize the model\n",
    "    x = Flatten()(base_vgg16.output)\n",
    "    predictions = Dense(num_labels, activation = 'sigmoid')(x)\n",
    "    model_vgg16 = Model(input = base_vgg16.input, output = predictions)\n",
    "\n",
    "model_vgg16_gpu = multi_gpu_model(model_vgg16, gpus = number_of_gpus)\n",
    "\n",
    "model_vgg16_gpu.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_vgg16_gpu.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Fit model\n",
    "\n",
    "model_vgg16_gpu.fit(X_train, y_train,\n",
    "                     batch_size = 16,\n",
    "                     epochs= 10,\n",
    "                     validation_data = (X_val, y_val),\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Save model trained\n",
    "\n",
    "model_vgg16.save('model_vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load model\n",
    "\n",
    "# model_vgg16 = load_model('model_vgg16.h5')\n",
    "\n",
    "# model_vgg16_gpu = multi_gpu_model(model_vgg16, gpus = number_of_gpus)\n",
    "\n",
    "# model_vgg16_gpu.compile(loss='binary_crossentropy', # try hinge loss function\n",
    "#                            optimizer=keras.optimizers.Adadelta(),\n",
    "#                            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Calculate predictions in validation dataset\n",
    "\n",
    "y_val_pred_vgg16 = model_vgg16_gpu.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Predict labels\n",
    "\n",
    "threshold = 0.22\n",
    "y_val_pred_label_vgg16 = y_val_pred_vgg16.copy()\n",
    "y_val_pred_label_vgg16[y_val_pred_vgg16>=threshold] = 1\n",
    "y_val_pred_label_vgg16[y_val_pred_vgg16<threshold] = 0\n",
    "\n",
    "## Calculate F1 score micro average\n",
    "f1_score_micro_vgg16 = f1_score(y_true=y_val, y_pred=y_val_pred_label_vgg16, average='micro')\n",
    "f1_score_micro_vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Output F1 score of VGG16 base learner model\n",
    "\n",
    "print(f1_score_micro_vgg16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blending model NN using two previous base learners as inputs\n",
    "#### - The idea is to split the validation dataset into two datasets (50-50)\n",
    "#### - First split will be used for training the blended model\n",
    "#### - Second split will be used for validating the blended model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Construct train and validation for blended model\n",
    "\n",
    "blended_X_train, blended_X_val, blended_y_train, blended_y_val = train_test_split(X_val, y_val, test_size=0.5, random_state=0)\n",
    "\n",
    "blended_X_train = np.concatenate((model_xception_gpu.predict(blended_X_train)\n",
    "                                   , model_vgg16_gpu.predict(blended_X_train))\n",
    "                                  , axis = 1)\n",
    "                                  \n",
    "blended_X_val = np.concatenate((model_xception_gpu.predict(blended_X_val)\n",
    "                                   , model_vgg16_gpu.predict(blended_X_val))\n",
    "                                  ,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Construct CNN model\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    #initialize the model\n",
    "    blended_network = Sequential()\n",
    "    blended_network.add(Dense(int(num_labels*1.5), input_dim=num_labels*2)) ## Number of neuros is mean of input and output dimension\n",
    "    blended_network.add(Activation('relu'))\n",
    "    blended_network.add(Dense(num_labels))\n",
    "    blended_network.add(Activation('sigmoid'))\n",
    "\n",
    "blended_network_gpu = multi_gpu_model(blended_network, gpus = number_of_gpus)\n",
    "\n",
    "blended_network_gpu.compile(loss='binary_crossentropy', # try hinge loss function\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blended_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Fit model\n",
    "\n",
    "blended_network_gpu.fit(blended_X_train, blended_y_train,\n",
    "                     batch_size = 16,\n",
    "                     epochs= 40,\n",
    "                     blended_data = (blended_X_val, blended_y_val),\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Save the blended model\n",
    "\n",
    "blended_network.save('blended_network_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Calculate predictions for blended validation dataset\n",
    "\n",
    "blended_y_val_pred = blended_network_gpu.predict(blended_X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Predict labels\n",
    "\n",
    "blended_threshold = 0.325 # Choose different thresholds\n",
    "blended_y_val_pred_label = blended_y_val_pred.copy()\n",
    "blended_y_val_pred_label[blended_y_val_pred>=blended_threshold] = 1\n",
    "blended_y_val_pred_label[blended_y_val_pred<blended_threshold] = 0\n",
    "\n",
    "## Calculate F1 score micro average\n",
    "blended_f1_score_micro = f1_score(y_true=blended_y_val, y_pred=blended_y_val_pred_label, average='micro')\n",
    "blended_f1_score_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Output F1 score of blended model\n",
    "\n",
    "print(blended_f1_score_micro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate predictions on test dataset and output Kaggle submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Construct test dataset for blended model\n",
    "blended_X_test = np.concatenate((model_xception_gpu.predict(X_test)\n",
    "                                   , model_vgg16_gpu.predict(X_test))\n",
    "                                  , axis = 1)\n",
    "\n",
    "## Calculate predictions with blended model\n",
    "blended_y_test_pred = blended_network_gpu.predict(blended_X_test)\n",
    "\n",
    "## Predict labels for test data\n",
    "blended_y_test_pred_label = blended_y_test_pred.copy()\n",
    "blended_y_test_pred_label[blended_y_test_pred >= blended_threshold] = 1\n",
    "blended_y_test_pred_label[blended_y_test_pred < blended_threshold] = 0\n",
    "\n",
    "blended_y_test_labels = []\n",
    "for result in blended_y_test_pred_label:\n",
    "    blended_y_test_labels.append(' '.join(list(mlb.classes_[result == 1])))\n",
    "\n",
    "blended_test_submission = pd.DataFrame({'image_id': list(test_data['image_id'])\n",
    "                                , 'label_id': blended_y_test_labels\n",
    "                               })\n",
    "\n",
    "blended_test_submission.to_csv('test_submission_05182018_v4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['133' '170' '184' '222' '66' '78']\n",
      "['133' '170' '222' '44' '66']\n"
     ]
    }
   ],
   "source": [
    "## Output an example of label predictions from the blended model\n",
    "\n",
    "print(mlb.classes_[blended_y_test_pred_label[0]==1])\n",
    "print(mlb.classes_[y_val[0]==1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
